{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab6a31f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import csv\n",
    "import tqdm\n",
    "from transformers import AutoProcessor, WhisperForConditionalGeneration\n",
    "from pydub import AudioSegment\n",
    "from util import audiosegment_to_array, transcribe_batch, create_filler\n",
    "\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"mps\" if t.backends.mps.is_available() else \"cpu\")\n",
    "model_id = \"openai/whisper-small\"\n",
    "sr=16000\n",
    "random.seed(100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8051744",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_id).to(device)\n",
    "model.generation_config.language = \"english\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "processor.feature_extractor.return_attention_mask = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee1a1694",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_trial(condition, target, talker, n_continuum):\n",
    "    # identify target\n",
    "    endpoints = target.split(\"_\")\n",
    "    c_target = endpoints[0] if condition == 'voiced' else endpoints[1]\n",
    "\n",
    "    # Get the primes for that target\n",
    "    frame_dir = f\"audio/primes/{talker}/{condition}/{c_target}\"\n",
    "    frames = os.listdir(frame_dir)\n",
    "    frames = [f for f in frames if f != '.DS_Store']\n",
    "    random.shuffle(frames)\n",
    "\n",
    "    silence = AudioSegment.silent(duration=500)\n",
    "    combined = AudioSegment.silent(duration=0)\n",
    "\n",
    "    # Add each prime to the combined audio\n",
    "    for f in frames:\n",
    "        audio = AudioSegment.from_wav(f'{frame_dir}/{f}')\n",
    "        combined += audio + silence\n",
    "    \n",
    "    trials = [combined + AudioSegment.from_wav(f'audio/MP/{talker}/continuum/{target}_1_{i}.wav') + silence for i in range(n_continuum)]\n",
    "    return trials, frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcabe219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50359]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.81s/it]\n"
     ]
    }
   ],
   "source": [
    "def semantic_adaptation(output_path, talkers, n_continuum, n_primes, n_trials):\n",
    "    with open(output_path, \"w\", newline=\"\") as f:\n",
    "        # Prep csv\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"id\", \"talker\", \"condition\", \"context\", \"transcript\", \"target\", \"target_step\"])\n",
    "\n",
    "        for t in talkers:\n",
    "            # Get primary audio paths\n",
    "            targets = os.listdir(f'audio/MP/{t}/continuum')\n",
    "            targets = list(set([re.search(r'([a-zA-Z]+_[a-zA-Z]+)_[0-9]', target).group(1) for target in targets]))\n",
    "            fillers = os.listdir(f'audio/fillers/{t}')\n",
    "            fillers = [f for f in fillers if f != '.DS_Store']\n",
    "\n",
    "            # A \"trial\" here represents every time a target is selected. Iterate throught the three conditions and every step of the continuum for each.\n",
    "            for n in tqdm.tqdm(range(n_trials)):\n",
    "                target = targets[n % len(targets)]\n",
    "\n",
    "                for c in ['voiced', 'voiceless', 'control']:\n",
    "                    if c == 'voiced':\n",
    "                        audio, frames = create_trial(c, target, t, n_continuum)\n",
    "                    elif c == 'voiceless':\n",
    "                        audio, frames = create_trial(c, target, t, n_continuum)\n",
    "                    else:\n",
    "                        random.shuffle(fillers)\n",
    "                        control_frames = fillers[:n_primes-1]\n",
    "                        audio, frames = create_filler(target, control_frames, t, n_continuum)\n",
    "\n",
    "                    transcript = transcribe_batch(audio, processor, model, sr, device, batch_size=n_continuum)\n",
    "                    for i in range(n_continuum):\n",
    "                        row = [n, t, c, frames, transcript[i], target, i]\n",
    "                        writer.writerow(row)\n",
    "\n",
    "# semantic_adaptation('data/SemAd.csv', ['hope'], 13, 20, 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "perc_learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
