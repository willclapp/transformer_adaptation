{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8045a6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import csv\n",
    "import tqdm\n",
    "from transformers import AutoProcessor, WhisperForConditionalGeneration\n",
    "from pydub import AudioSegment\n",
    "from util import audiosegment_to_array, transcribe_batch, create_filler\n",
    "\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"mps\" if t.backends.mps.is_available() else \"cpu\")\n",
    "model_id = \"openai/whisper-small\"\n",
    "sr=16000\n",
    "random.seed(100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7533b7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_id).to(device)\n",
    "model.generation_config.language = \"english\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "processor.feature_extractor.return_attention_mask = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "159beb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_trial(condition, target, frames, talker, n_continuum):\n",
    "    endpoints = target.split(\"_\")\n",
    "    frames = [f for f in frames if endpoints[0] not in f and endpoints[1] not in f]\n",
    "    random.shuffle(frames)\n",
    "\n",
    "    silence = AudioSegment.silent(duration=500)\n",
    "    combined = AudioSegment.silent(duration=0)\n",
    "    for f in frames:\n",
    "        audio = AudioSegment.from_wav(f'audio/MP/{talker}/{condition}/{f}')\n",
    "        combined += audio + silence\n",
    "    \n",
    "    trials = [combined + AudioSegment.from_wav(f'audio/MP/{talker}/continuum/{target}_1_{i}.wav') + silence for i in range(n_continuum)]\n",
    "    return trials, frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b55dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50359]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
      "100%|██████████| 1/1 [00:10<00:00, 10.70s/it]\n"
     ]
    }
   ],
   "source": [
    "def selective_adaptation(output_path, talkers, n_continuum, n_trials):\n",
    "    with open(output_path, \"w\", newline=\"\") as f:\n",
    "        # Prep csv\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"id\", \"talker\", \"condition\", \"context\", \"transcript\", \"target\", \"target_step\"])\n",
    "        for t in talkers:\n",
    "            # Get all the audio paths\n",
    "            targets = os.listdir(f'audio/MP/{t}/continuum')\n",
    "            targets = list(set([re.search(r'([a-zA-Z]+_[a-zA-Z]+)_[0-9]', target).group(1) for target in targets]))\n",
    "            voiced = os.listdir(f'audio/MP/{t}/voiced')\n",
    "            voiced = [v for v in voiced if v != '.DS_Store']\n",
    "            voiceless = os.listdir(f'audio/MP/{t}/voiceless')\n",
    "            voiceless = [v for v in voiceless if v != '.DS_Store']\n",
    "            fillers = os.listdir(f'audio/fillers/{t}')\n",
    "            fillers = [f for f in fillers if f != '.DS_Store']\n",
    "\n",
    "            # A \"trial\" here represents every time a target is selected. Iterate throught the three conditions and every step of the continuum for each.\n",
    "            for n in tqdm.tqdm(range(n_trials)):\n",
    "                target = targets[n % len(targets)]\n",
    "\n",
    "                for c in ['voiced', 'voiceless', 'control']:\n",
    "                    if c == 'voiced':\n",
    "                        audio, frames = create_trial(c, target, voiced, t, n_continuum)\n",
    "                    elif c == 'voiceless':\n",
    "                        audio, frames = create_trial(c, target, voiceless, t, n_continuum)\n",
    "                    else:\n",
    "                        random.shuffle(fillers)\n",
    "                        control_frames = fillers[:len(voiced)-1]\n",
    "                        audio, frames = create_filler(target, control_frames, t, n_continuum)\n",
    "\n",
    "                    transcript = transcribe_batch(audio, processor, model, sr, device, batch_size=n_continuum)\n",
    "                    for i in range(n_continuum):\n",
    "                        \n",
    "                        row = [n, t, c, frames, transcript[i], target, i]\n",
    "                        writer.writerow(row)\n",
    "\n",
    "# selective_adaptation('data/SelAd.csv', ['hope'], 13, 300)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "perc_learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
